# Evolving Agents Labs

## About Our Research

We explore early-stage concepts in adaptive AI through experimental frameworks and research prototypes. Our work investigates how intelligent agents might adapt, learn, and evolve their behavior based on context, user interaction, and accumulated experience.

**All projects remain permanently in alpha status as ongoing research experiments.**

---

## 📢 Project Evolution Announcement

### Original Evolving Agents Toolkit (EAT) - Sunset Notice

The original [Evolving Agents Toolkit (EAT) Python project](https://github.com/matiasmolinas/evolving-agents) has been **officially discontinued** as of July 2025. While EAT demonstrated powerful concepts in multi-agent orchestration with MongoDB backend, we recognized that the complex Python architecture was over-engineered for achieving adaptive agent behavior.

**Key insights from EAT that led to our new direction:**
- Complex multi-component architectures created unnecessary overhead
- The core concept of autonomous agent evolution was sound
- Simpler approaches could achieve the same adaptive behaviors
- LLM capabilities alone could handle orchestration and evolution

### Evolution to LLMunix

The concepts pioneered in EAT have been **dramatically simplified and reimplemented** in our new flagship project: **LLMunix** - a Pure Markdown Operating System that achieves the same adaptive agent goals through elegant simplicity.

**From EAT's complexity to LLMunix's simplicity:**
- **EAT**: Multi-component Python architecture with MongoDB backend
- **LLMunix**: Pure markdown definitions interpreted by LLM runtime engines
- **Result**: Same adaptive capabilities, 10x simpler implementation

### Current Focus & Next Steps

We are actively **maintaining and evolving LLMunix** as our core research platform. However, with the recent implementation of **sub-agents in markdown as an official Claude Code feature**, we now understand that our original markdown-based agent concept was an excellent proof-of-concept that has been validated by the industry.

**Our new research direction:**
- **LLMunix continues** as a maintained research platform for markdown-based agent systems
- **Next frontier**: Implementing agents and their tools **directly at the LLM level**
- **Goal**: Move beyond markdown specifications to native LLM-based agent architectures
- **Focus**: Developing truly autonomous agents that exist within the LLM's reasoning space

This represents the natural evolution from external frameworks → markdown specifications → **pure LLM-native agent implementation**.

---

## 🧪 Current Experiments

### [LLMunix](https://github.com/EvolvingAgentsLabs/llmunix) `ALPHA`
**Pure Markdown Operating System**
- Revolutionary Pure Markdown Operating System designed to be run by multiple AI runtime engines
- Compatible with Claude Code and Claude Code sub agents, Gemini CLI, and Qwen Code
- Features multi-tier memory, inter-agent messaging, and dynamic evolution capabilities
- Runtime engines interpret the manifest file to turn markdown specifications into a functional operating system

[📖 Learn More](https://evolvingagentslabs.github.io/experiments/llmunix.html) • [🚀 View Project](https://github.com/EvolvingAgentsLabs/llmunix)

### [Agent Forge](https://github.com/EvolvingAgentsLabs/agent-forge) `ALPHA`
**Self-Compiling Agent Architecture**
- Revolutionary unified architecture using a single fine-tuned Qwen2.5-Coder model for both orchestration and code translation
- Features just-in-time code compilation, dynamic tool generation, and benchmarkable performance improvements over pure LLM approaches
- Includes comprehensive Google Colab guide for replication with Unsloth optimization

[📖 Learn More](https://evolvingagentslabs.github.io/experiments/agent-forge.html) • [🚀 View Project](https://github.com/EvolvingAgentsLabs/agent-forge)

#### JIT Agent Components

- **[jit-agent-poc](https://github.com/EvolvingAgentsLabs/jit-agent-poc)** `ALPHA` - Unified architecture proof-of-concept using a single fine-tuned Qwen2.5-Coder-1.5B model as both Orchestrator and Translator, eliminating multi-model complexity through specialized LoRA training with Unsloth
- **[jit-agent-learn](https://github.com/EvolvingAgentsLabs/jit-agent-learn)** `ALPHA` - Extension focused on reinforcement learning capabilities, allowing agents to improve their performance through experience and feedback loops
- **[jit-agent-memory](https://github.com/EvolvingAgentsLabs/jit-agent-memory)** `ALPHA` - Adds persistent memory capabilities to enable contextual awareness and long-term information retention across interactions

---

## 🔬 Research Areas

| Focus Area | Description |
|------------|-------------|
| **Adaptive Behavior Research** | How agents might modify decision-making based on context and interaction patterns |
| **Pure Markdown Architecture** | Exploring the use of markdown as a full operating system specification, enabling clean separation of behavior, state, and execution logic |
| **JIT Compilation Systems** | Dynamic compilation of executable code from LLM-provided conceptual ideas for enhanced performance |
| **Memory System Experiments** | Persistent memory capabilities for contextual awareness and long-term information retention |
| **Self-Improving Learning** | Reinforcement learning capabilities allowing agents to improve through experience and feedback loops |
| **Hybrid Agent Architectures** | Combining multiple AI models and fine-tuned components for enhanced agent capabilities |

---

## 🌐 Explore Our Research Lab

**👉 [Visit evolvingagentslabs.github.io](https://evolvingagentslabs.github.io) for the complete research showcase**

### Quick Navigation
- 🔬 [View All Experiments](https://evolvingagentslabs.github.io#experiments)
- 📊 [Research Overview](https://evolvingagentslabs.github.io#about)  
- 📖 [LLMunix Deep Dive](https://evolvingagentslabs.github.io/experiments/llmunix.html)
- 🛠️ [Try LLMunix](https://github.com/EvolvingAgentsLabs/llmunix#quick-start)

---

## ⚠️ Experimental Nature

**Important**: All our projects are research prototypes exploring early-stage concepts. They should be treated as experimental research material rather than production-ready systems. We believe in transparent, open research that advances the field through shared exploration.

---

## 🤝 Contributing

We welcome researchers, developers, and curious minds to explore our work:

- **🔍 Explore**: Browse our experiments and documentation
- **🐛 Report**: Share findings or issues you discover  
- **💡 Discuss**: Join conversations about adaptive agent concepts
- **🧪 Experiment**: Build upon our research prototypes

---

## 📄 License

All projects are released under the Apache 2.0 License.